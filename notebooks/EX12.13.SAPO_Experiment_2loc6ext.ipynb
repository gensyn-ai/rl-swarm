{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# SAPO Experiment: Config 3 (2 Local / 6 External)\n",
    "\n",
    "This notebook replicates **Configuration 3** from the SAPO paper:\n",
    "- **I = 2**: Generate only 2 rollouts locally per round\n",
    "- **J = 6**: Fetch 6 external rollouts from swarm peers\n",
    "- **G = 8**: Generate 8 completions per question\n",
    "- **Rounds = 2000**: Train for 2000 rounds\n",
    "\n",
    "This configuration explores **heavy swarm dependence** (75% external experience).\n",
    "\n",
    "**Expected Performance:**\n",
    "- Cumulative reward after 2000 rounds: ~946\n",
    "- **+68% improvement** over baseline (no sharing)\n",
    "- **WORSE than 4/4** despite more external data!\n",
    "\n",
    "**Why This Underperforms 4/4:**\n",
    "- Too few local rollouts (only 2) limits exploration\n",
    "- Over-reliance on external experience can cause instability\n",
    "- Local innovation is critical for swarm diversity\n",
    "- Demonstrates that \"more external â‰  better\"\n",
    "\n",
    "**Setup Requirements:**\n",
    "1. Run ONE coordinator node (set `NODE_ROLE = 'coordinator'`)\n",
    "2. Run 7+ worker nodes (use `NODE_ROLE = 'worker'`, unique NODE_IDs)\n",
    "3. All nodes must use same `EXPERIMENT_NAME`\n",
    "4. All nodes must use same Google Drive account\n",
    "\n",
    "**Paper Reference:** arXiv:2509.08721 - SAPO (Section 5.2, Table 1, Row 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-cell"
   },
   "outputs": [],
   "source": [
    "# Experiment Configuration\n",
    "EXPERIMENT_NAME = 'sapo_config3_2loc6ext'  # MUST BE SAME ACROSS ALL NODES\n",
    "NODE_ROLE = 'coordinator'  # 'coordinator' for first node, 'worker' for others\n",
    "NODE_ID = 'node_0'  # MUST BE UNIQUE (node_0, node_1, node_2, etc.)\n",
    "\n",
    "# Model Configuration\n",
    "MODEL_NAME = 'Gensyn/Qwen2.5-0.5B-Instruct'  # Same as paper\n",
    "SEED = 42  # For reproducibility\n",
    "\n",
    "# SAPO Configuration (Config 3: 2/6)\n",
    "NUM_TRAIN_SAMPLES = 2        # I: Local rollouts per round (MINIMAL)\n",
    "NUM_TRANSPLANT_TREES = 6     # J: External rollouts from swarm (MAXIMUM)\n",
    "NUM_GENERATIONS = 8          # G: Completions per question\n",
    "MAX_ROUNDS = 2000            # Train for 2000 rounds (same as paper)\n",
    "\n",
    "# Coordinator Configuration (only used if NODE_ROLE='coordinator')\n",
    "ADVANCEMENT_STRATEGY = 'hybrid'  # 'time_based', 'completion_based', or 'hybrid'\n",
    "ROUND_DURATION_MINUTES = 15      # How long to wait for peers per round\n",
    "MIN_SUBMISSION_PERCENT = 0.5     # Minimum % of peers before advancing\n",
    "MAX_ROUND_DURATION_MINUTES = 30  # Maximum wait time\n",
    "\n",
    "# Rollout Sharing Configuration\n",
    "ROLLOUT_PUBLISH_FREQUENCY = 'stage'  # When to share rollouts\n",
    "ROLLOUT_CLEANUP_ENABLED = True       # Enable cleanup (2000 rounds = lots of data)\n",
    "ROLLOUT_KEEP_LAST_N_ROUNDS = 20      # Keep recent rollouts only\n",
    "ROLLOUT_ARCHIVE_OLD = False          # Don't archive (saves space)\n",
    "\n",
    "# Optional: HuggingFace Token\n",
    "HUGGINGFACE_TOKEN = None  # Set to your token or keep None\n",
    "\n",
    "\n",
    "print(f\"âœ“ Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"âœ“ Node Role: {NODE_ROLE}\")\n",
    "print(f\"âœ“ Node ID: {NODE_ID}\")\n",
    "print(f\"âœ“ Configuration: I={NUM_TRAIN_SAMPLES}, J={NUM_TRANSPLANT_TREES}, G={NUM_GENERATIONS}\")\n",
    "print(f\"âœ“ Model: {MODEL_NAME}\")\n",
    "print(f\"âœ“ Max Rounds: {MAX_ROUNDS}\")\n",
    "print()\n",
    "print(\"âš ï¸  Config 3: Heavy swarm dependence (75% external)\")\n",
    "print(\"   Expected cumulative reward: ~946 (+68% vs baseline)\")\n",
    "print(\"   Note: Worse than 4/4 config despite more external data!\")\n",
    "print()\n",
    "if NODE_ROLE == 'coordinator':\n",
    "    print(\"ðŸ“¡ Running as COORDINATOR - will manage round progression\")\n",
    "else:\n",
    "    print(\"ðŸ‘· Running as WORKER - will follow coordinator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mount"
   },
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-cell"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set base path (MUST BE SAME ACROSS ALL NODES)\n",
    "GDRIVE_BASE_PATH = '/content/drive/MyDrive/rl-swarm'\n",
    "os.makedirs(GDRIVE_BASE_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"âœ“ Google Drive mounted at: {GDRIVE_BASE_PATH}\")\n",
    "\n",
    "# Check if experiment exists (for workers)\n",
    "if NODE_ROLE == 'worker':\n",
    "    experiment_path = os.path.join(GDRIVE_BASE_PATH, 'experiments', EXPERIMENT_NAME)\n",
    "    if not os.path.exists(experiment_path):\n",
    "        print(f\"âš ï¸  Experiment '{EXPERIMENT_NAME}' not found!\")\n",
    "        print(f\"   Expected at: {experiment_path}\")\n",
    "        print()\n",
    "        print(\"Make sure:\")\n",
    "        print(\"  1. Coordinator is running\")\n",
    "        print(\"  2. Coordinator has initialized the experiment (cell 4)\")\n",
    "        print(\"  3. EXPERIMENT_NAME matches the coordinator\")\n",
    "        raise FileNotFoundError(f\"Experiment not found: {EXPERIMENT_NAME}\")\n",
    "    else:\n",
    "        print(f\"âœ“ Found experiment: {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpu"
   },
   "source": [
    "## 3. System Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu-cell"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ“ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU detected - training will be slow\")\n",
    "    print(\"  Consider: Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-cell"
   },
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "import os\n",
    "\n",
    "# Change to safe directory first\n",
    "%cd /content\n",
    "\n",
    "# Remove existing directory if it exists\n",
    "if os.path.exists('/content/rl-swarm'):\n",
    "    print(\"Removing existing repository...\")\n",
    "    !rm -rf /content/rl-swarm\n",
    "\n",
    "# Clone fresh copy\n",
    "print(\"Cloning repository...\")\n",
    "!git clone https://github.com/Elrashid/rl-swarm.git /content/rl-swarm\n",
    "\n",
    "# Change to repo directory\n",
    "%cd /content/rl-swarm\n",
    "\n",
    "# Verify clone worked\n",
    "if not os.path.exists('requirements.txt'):\n",
    "    print(\"âŒ Clone failed! requirements.txt not found\")\n",
    "    raise FileNotFoundError(\"Repository clone failed\")\n",
    "\n",
    "print(\"âœ“ Repository cloned successfully\")\n",
    "\n",
    "# Install dependencies\n",
    "print(\"Installing dependencies (this may take 3-5 minutes)...\")\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q gensyn-genrl==0.1.9\n",
    "\n",
    "print(\"âœ“ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init"
   },
   "source": [
    "## 4. Initialize Experiment (Coordinator Only)\n",
    "\n",
    "**âš ï¸ Run this cell ONLY on the coordinator node!**\n",
    "\n",
    "Workers should skip this cell - the coordinator will create the experiment structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init-cell"
   },
   "outputs": [],
   "source": [
    "if NODE_ROLE == 'coordinator':\n",
    "    from rgym_exp.utils.experiment_manager import init_experiment\n",
    "    \n",
    "    # Initialize experiment structure in Google Drive\n",
    "    config_overrides = {\n",
    "        'training.max_round': MAX_ROUNDS,\n",
    "        'training.num_generations': NUM_GENERATIONS,\n",
    "        'training.num_transplant_trees': NUM_TRANSPLANT_TREES,\n",
    "        'training.num_train_samples': NUM_TRAIN_SAMPLES,\n",
    "        'training.seed': SEED,\n",
    "        'coordinator_manager.advancement_strategy': ADVANCEMENT_STRATEGY,\n",
    "        'coordinator_manager.round_duration_minutes': ROUND_DURATION_MINUTES,\n",
    "        'coordinator_manager.min_submission_percent': MIN_SUBMISSION_PERCENT,\n",
    "        'coordinator_manager.max_round_duration_minutes': MAX_ROUND_DURATION_MINUTES,\n",
    "    }\n",
    "    \n",
    "    init_experiment(\n",
    "        gdrive_base_path=GDRIVE_BASE_PATH,\n",
    "        experiment_name=EXPERIMENT_NAME,\n",
    "        config_overrides=config_overrides\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Experiment initialized: {EXPERIMENT_NAME}\")\n",
    "    print(f\"  Path: {GDRIVE_BASE_PATH}/experiments/{EXPERIMENT_NAME}\")\n",
    "    print(f\"  Config: I={NUM_TRAIN_SAMPLES}, J={NUM_TRANSPLANT_TREES}, G={NUM_GENERATIONS}\")\n",
    "    print()\n",
    "    print(\"âœ“ Workers can now join this experiment!\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Skipping initialization (worker node)\")\n",
    "    print(\"  Coordinator will create the experiment structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "env"
   },
   "source": [
    "## 5. Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "env-cell"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['GDRIVE_PATH'] = GDRIVE_BASE_PATH\n",
    "os.environ['EXPERIMENT_NAME'] = EXPERIMENT_NAME\n",
    "os.environ['NODE_ROLE'] = NODE_ROLE\n",
    "os.environ['NODE_ID'] = NODE_ID or f\"node_{uuid.uuid4().hex[:8]}\"\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "os.environ['SEED'] = str(SEED)\n",
    "\n",
    "# SAPO configuration\n",
    "os.environ['NUM_TRAIN_SAMPLES'] = str(NUM_TRAIN_SAMPLES)\n",
    "os.environ['NUM_TRANSPLANT_TREES'] = str(NUM_TRANSPLANT_TREES)\n",
    "os.environ['NUM_GENERATIONS'] = str(NUM_GENERATIONS)\n",
    "os.environ['MAX_ROUNDS'] = str(MAX_ROUNDS)\n",
    "\n",
    "# Rollout configuration\n",
    "os.environ['ROLLOUT_PUBLISH_FREQUENCY'] = ROLLOUT_PUBLISH_FREQUENCY\n",
    "os.environ['ROLLOUT_CLEANUP_ENABLED'] = str(ROLLOUT_CLEANUP_ENABLED)\n",
    "os.environ['ROLLOUT_KEEP_LAST_N_ROUNDS'] = str(ROLLOUT_KEEP_LAST_N_ROUNDS)\n",
    "os.environ['ROLLOUT_ARCHIVE_OLD'] = str(ROLLOUT_ARCHIVE_OLD)\n",
    "\n",
    "if HUGGINGFACE_TOKEN:\n",
    "    os.environ['HUGGINGFACE_ACCESS_TOKEN'] = HUGGINGFACE_TOKEN\n",
    "\n",
    "\n",
    "print(\"âœ“ Environment variables set\")\n",
    "print(f\"  Node ID: {os.environ['NODE_ID']}\")\n",
    "print(f\"  Role: {NODE_ROLE}\")\n",
    "print(f\"  Config: I={NUM_TRAIN_SAMPLES}, J={NUM_TRANSPLANT_TREES}, G={NUM_GENERATIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train"
   },
   "source": [
    "## 6. Start Training\n",
    "\n",
    "**This cell will run for ~24-48 hours (2000 rounds).**\n",
    "\n",
    "The training will:\n",
    "- Generate only 2 local rollouts per round (minimal local exploration)\n",
    "- Fetch 6 external rollouts from swarm peers (75% external!)\n",
    "- Train using GRPO algorithm with heavy external dependence\n",
    "- Share rollouts with other nodes after each stage\n",
    "- Save checkpoints every 10 rounds\n",
    "\n",
    "**Expected outcome:**\n",
    "- Good improvement over baseline (+68%)\n",
    "- BUT worse than 4/4 config despite more external data\n",
    "- Demonstrates importance of local/external balance\n",
    "\n",
    "**Monitor progress:**\n",
    "- Use `EX12.02.RL_Swarm_Monitoring.ipynb` in a separate tab\n",
    "- Check peer discovery: Should see 8+ active peers\n",
    "\n",
    "**Press stop button to gracefully shutdown.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-cell"
   },
   "outputs": [],
   "source": [
    "from rgym_exp.utils.notebook_utils import run_with_live_output\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Starting SAPO Config 3 Experiment\")\n",
    "print(f\"Configuration: I={NUM_TRAIN_SAMPLES}, J={NUM_TRANSPLANT_TREES}, G={NUM_GENERATIONS}\")\n",
    "print(f\"Node: {NODE_ID} ({NODE_ROLE})\")\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Max Rounds: {MAX_ROUNDS}\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Run training with live output\n",
    "exit_code = run_with_live_output([\n",
    "    sys.executable, '-m', 'rgym_exp.runner.swarm_launcher'\n",
    "])\n",
    "\n",
    "if exit_code == -1:\n",
    "    print(\"\\nâš ï¸  Training interrupted by user\")\n",
    "elif exit_code != 0:\n",
    "    print(f\"\\nâŒ Training exited with code: {exit_code}\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Training completed successfully\")\n",
    "    print(f\"   Total rounds: {MAX_ROUNDS}\")\n",
    "    print(f\"   Expected cumulative reward: ~946 (+68% vs baseline)\")\n",
    "    print(f\"   Note: Config 2 (4/4) achieves +94% with less external data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## 7. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results-cell"
   },
   "outputs": [],
   "source": [
    "from rgym_exp.utils.experiment_manager import get_experiment_status, get_experiment_metrics\n",
    "import pandas as pd\n",
    "\n",
    "# Get current status\n",
    "status = get_experiment_status(GDRIVE_BASE_PATH, EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Configuration: Config 3 (I=2, J=6, G=8)\")\n",
    "print(f\"Current Round: {status.get('current_round', 0)} / {MAX_ROUNDS}\")\n",
    "print(f\"Active Peers: {status.get('active_peers', 0)}\")\n",
    "print()\n",
    "\n",
    "# Load and display metrics for this node\n",
    "try:\n",
    "    df = get_experiment_metrics(GDRIVE_BASE_PATH, EXPERIMENT_NAME)\n",
    "    if not df.empty:\n",
    "        # Filter to this node\n",
    "        node_df = df[df['node_id'] == NODE_ID]\n",
    "        if not node_df.empty:\n",
    "            cumulative_reward = node_df['my_reward'].sum()\n",
    "            print(f\"Cumulative Reward ({NODE_ID}): {cumulative_reward:.2f}\")\n",
    "            print(f\"Expected (paper): ~946\")\n",
    "            print(f\"Baseline: ~562\")\n",
    "            print(f\"Config 2 (4/4): ~1093\")\n",
    "            improvement = ((cumulative_reward / 562) - 1) * 100 if cumulative_reward > 0 else 0\n",
    "            print(f\"Improvement vs baseline: +{improvement:.1f}%\")\n",
    "            print()\n",
    "            \n",
    "            # Show recent rounds\n",
    "            print(\"Recent rounds (last 10):\")\n",
    "            recent = node_df.tail(10)\n",
    "            print(recent[['round', 'stage', 'my_reward']].to_string(index=False))\n",
    "        else:\n",
    "            print(f\"No metrics for {NODE_ID} yet\")\n",
    "    else:\n",
    "        print(\"No metrics available yet\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load metrics: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# === Real-Time Progress Viewer ===\n# Run this cell anytime to check progress from GDrive\n# Useful if you reconnect after notebook disconnect\n\nimport sys\nsys.path.append('/content/rl-swarm')\n\nfrom rgym_exp.utils.progress_tracker import get_experiment_progress\n\nprogress = get_experiment_progress(GDRIVE_BASE_PATH, EXPERIMENT_NAME)\n\nprint(\"=\"*70)\nprint(\"ðŸ“Š REAL-TIME PROGRESS FROM GDRIVE\")\nprint(\"=\"*70)\nprint(f\"Experiment: {progress.get('experiment')}\")\nprint()\n\nfor node_id, node_data in progress.get('nodes', {}).items():\n    if 'error' in node_data:\n        print(f\"  {node_id}: {node_data['error']}\")\n    else:\n        elapsed_hours = node_data.get('elapsed_seconds', 0) / 3600\n        print(f\"  {node_id}:\")\n        print(f\"    Latest event: {node_data.get('latest_event')}\")\n        print(f\"    Current round: {node_data.get('latest_round')}\")\n        print(f\"    Elapsed time: {elapsed_hours:.1f} hours\")\n        print()\n\nprint(\"=\"*70)\nprint(\"Note: Progress updates every round. Logs flush every 30s to GDrive.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7.5. Check Real-Time Progress from GDrive (Optional)\n\n**Reconnected after disconnect?** Run this cell to check training progress:\n- Shows current round for each node\n- Displays elapsed time\n- Works even if your notebook disconnected\n\nProgress is saved to GDrive every round, logs flush every 30 seconds.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "resume"
   },
   "source": [
    "## 8. Resume Training (If Disconnected)\n",
    "\n",
    "If your Colab session disconnects:\n",
    "1. Re-run cells 1-3 (keep same EXPERIMENT_NAME and NODE_ID)\n",
    "2. Skip cell 4 (initialization - already done)\n",
    "3. Re-run cells 5-6 (env vars and training)\n",
    "4. System will automatically resume from last checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notes"
   },
   "source": [
    "## Notes\n",
    "\n",
    "### SAPO Config 3: Too Much External?\n",
    "\n",
    "This experiment uses:\n",
    "- **I = 2**: Only 2 local rollouts generated per round\n",
    "- **J = 6**: 6 external rollouts fetched from swarm\n",
    "- **G = 8**: 8 completions generated per question\n",
    "- **Total rollouts per round**: 8 (2 local + 6 external)\n",
    "- **External ratio**: 75% (6/8) - VERY HIGH\n",
    "\n",
    "### Expected Results\n",
    "\n",
    "From the SAPO paper (Table 1):\n",
    "- **Cumulative reward after 2000 rounds**: ~946\n",
    "- **Improvement over baseline**: +68% (baseline: ~562)\n",
    "- **WORSE than Config 2 (4/4)** which achieves +94%\n",
    "\n",
    "### Why More External Can Be Worse\n",
    "\n",
    "Performance comparison:\n",
    "```\n",
    "Config 2 (4/4):  50% external â†’ +94%  âœ“ BEST\n",
    "Config 3 (2/6):  75% external â†’ +68%  âœ— Worse despite more data!\n",
    "```\n",
    "\n",
    "Key insights:\n",
    "1. **Too few local rollouts** (only 2): Limited local exploration and innovation\n",
    "2. **Over-reliance on external**: Can create unstable training dynamics\n",
    "3. **Loss of diversity**: If all nodes rely heavily on external, swarm diversity decreases\n",
    "4. **Local matters**: Each node needs sufficient local exploration to contribute unique strategies\n",
    "\n",
    "### The Diversity Paradox\n",
    "\n",
    "When all nodes generate only 2 local rollouts:\n",
    "- Each node's contribution to swarm is limited\n",
    "- External rollouts become more homogeneous over time\n",
    "- Swarm loses the diversity that made collaboration effective\n",
    "- System converges to suboptimal strategies\n",
    "\n",
    "### Performance Comparison (All Configs)\n",
    "\n",
    "| Config | I | J | External % | Cumulative | Improvement |\n",
    "|--------|---|---|------------|------------|-------------|\n",
    "| Baseline | 8 | 0 | 0% | ~562 | - |\n",
    "| Config 1 | 6 | 2 | 25% | ~854 | +52% |\n",
    "| **Config 2** | **4** | **4** | **50%** | **~1093** | **+94%** |\n",
    "| Config 3 | 2 | 6 | 75% | ~946 | +68% |\n",
    "\n",
    "### Key Lesson\n",
    "\n",
    "**Balance is critical!**\n",
    "- More external data â‰  better performance\n",
    "- Need sufficient local exploration (at least 4 rollouts)\n",
    "- 50/50 split (Config 2) achieves optimal balance\n",
    "- Local innovation fuels swarm diversity\n",
    "\n",
    "### When To Use This Config\n",
    "\n",
    "This configuration is primarily useful for:\n",
    "- Understanding the importance of local/external balance\n",
    "- Demonstrating diminishing returns of external dependence\n",
    "- Research on swarm dynamics and diversity\n",
    "- Comparison studies (as in the SAPO paper)\n",
    "\n",
    "**For practical applications, use Config 2 (4/4) instead.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "EX12.13.SAPO_Experiment_2loc6ext",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}