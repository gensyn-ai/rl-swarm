{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# RL Swarm - Experiment Monitoring Dashboard\n",
    "\n",
    "This notebook provides monitoring and analysis tools for your RL Swarm experiments.\n",
    "\n",
    "**Features:**\n",
    "- ðŸ“Š Real-time experiment status\n",
    "- ðŸ“ˆ Training metrics visualization\n",
    "- ðŸ‘¥ Peer activity monitoring\n",
    "- ðŸ” Rollout inspection\n",
    "- âš ï¸ Error detection\n",
    "\n",
    "**Usage:**\n",
    "1. Mount Google Drive\n",
    "2. Configure experiment name\n",
    "3. Run monitoring cells\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q pandas matplotlib seaborn plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-header"
   },
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# =======================\n",
    "# CONFIGURE YOUR EXPERIMENT\n",
    "# =======================\n",
    "\n",
    "# Must match the experiment you want to monitor\n",
    "EXPERIMENT_NAME = 'my_first_experiment'\n",
    "\n",
    "# Base path (usually don't need to change)\n",
    "GDRIVE_BASE = '/content/drive/MyDrive/rl-swarm'\n",
    "\n",
    "# =======================\n",
    "# Derived paths\n",
    "EXPERIMENT_PATH = f'{GDRIVE_BASE}/experiments/{EXPERIMENT_NAME}'\n",
    "\n",
    "# Verify experiment exists\n",
    "if not os.path.exists(EXPERIMENT_PATH):\n",
    "    print(f\"âŒ Experiment '{EXPERIMENT_NAME}' not found!\")\n",
    "    print(f\"   Path checked: {EXPERIMENT_PATH}\")\n",
    "    print(\"\\nAvailable experiments:\")\n",
    "    exp_dir = f'{GDRIVE_BASE}/experiments'\n",
    "    if os.path.exists(exp_dir):\n",
    "        exps = [d for d in os.listdir(exp_dir) if os.path.isdir(os.path.join(exp_dir, d))]\n",
    "        for exp in exps:\n",
    "            print(f\"  - {exp}\")\n",
    "    else:\n",
    "        print(\"  (No experiments found)\")\n",
    "else:\n",
    "    print(f\"âœ… Monitoring experiment: {EXPERIMENT_NAME}\")\n",
    "    print(f\"   Path: {EXPERIMENT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "status-header"
   },
   "source": [
    "## 3. Experiment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "current-status"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def get_experiment_status(exp_path):\n",
    "    \"\"\"Get current experiment status.\"\"\"\n",
    "    status = {}\n",
    "    \n",
    "    # Read current round/stage\n",
    "    state_file = f\"{exp_path}/state/current_state.json\"\n",
    "    if os.path.exists(state_file):\n",
    "        with open(state_file) as f:\n",
    "            state = json.load(f)\n",
    "            status['round'] = state.get('round', 0)\n",
    "            status['stage'] = state.get('stage', 0)\n",
    "            status['last_updated'] = state.get('timestamp', 0)\n",
    "    else:\n",
    "        status['round'] = 0\n",
    "        status['stage'] = 0\n",
    "        status['last_updated'] = 0\n",
    "    \n",
    "    # Count active peers\n",
    "    peers_dir = f\"{exp_path}/peers\"\n",
    "    if os.path.exists(peers_dir):\n",
    "        status['num_peers'] = len(os.listdir(peers_dir))\n",
    "    else:\n",
    "        status['num_peers'] = 0\n",
    "    \n",
    "    # List peer IDs\n",
    "    if os.path.exists(peers_dir):\n",
    "        peers = []\n",
    "        for peer_file in os.listdir(peers_dir):\n",
    "            with open(f\"{peers_dir}/{peer_file}\") as f:\n",
    "                peer_data = json.load(f)\n",
    "                peers.append({\n",
    "                    'peer_id': peer_data.get('peer_id', 'unknown'),\n",
    "                    'registered_at': peer_data.get('timestamp', 0)\n",
    "                })\n",
    "        status['peers'] = peers\n",
    "    else:\n",
    "        status['peers'] = []\n",
    "    \n",
    "    return status\n",
    "\n",
    "# Get and display status\n",
    "status = get_experiment_status(EXPERIMENT_PATH)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"ðŸ“Š EXPERIMENT STATUS: {EXPERIMENT_NAME}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Current Round:  {status['round']}\")\n",
    "print(f\"Current Stage:  {status['stage']}\")\n",
    "print(f\"Active Peers:   {status['num_peers']}\")\n",
    "\n",
    "if status['last_updated'] > 0:\n",
    "    last_update = datetime.fromtimestamp(status['last_updated'])\n",
    "    print(f\"Last Updated:   {last_update.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nðŸ‘¥ Registered Peers:\")\n",
    "if status['peers']:\n",
    "    for peer in status['peers']:\n",
    "        peer_id = peer['peer_id']\n",
    "        registered = datetime.fromtimestamp(peer['registered_at']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"  - {peer_id[:16]}... (registered: {registered})\")\n",
    "else:\n",
    "    print(\"  (No peers registered yet)\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "metrics-header"
   },
   "source": [
    "## 4. Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-metrics"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_all_metrics(exp_path):\n",
    "    \"\"\"Load metrics from all nodes.\"\"\"\n",
    "    logs_dir = f\"{exp_path}/logs\"\n",
    "    \n",
    "    if not os.path.exists(logs_dir):\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    all_metrics = []\n",
    "    \n",
    "    for node_id in os.listdir(logs_dir):\n",
    "        metrics_file = f\"{logs_dir}/{node_id}/metrics.jsonl\"\n",
    "        \n",
    "        if not os.path.exists(metrics_file):\n",
    "            continue\n",
    "        \n",
    "        # Read JSONL file\n",
    "        with open(metrics_file) as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    metric = json.loads(line.strip())\n",
    "                    metric['node_id'] = node_id\n",
    "                    all_metrics.append(metric)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    \n",
    "    if not all_metrics:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(all_metrics)\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load metrics\n",
    "print(\"Loading metrics...\")\n",
    "df = load_all_metrics(EXPERIMENT_PATH)\n",
    "\n",
    "if df.empty:\n",
    "    print(\"âŒ No metrics found. Training may not have started yet.\")\n",
    "else:\n",
    "    print(f\"âœ… Loaded {len(df)} metric records from {df['node_id'].nunique()} nodes\")\n",
    "    print(f\"   Rounds: {df['round'].min()} - {df['round'].max()}\")\n",
    "    print(f\"\\nSample metrics:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot-rewards"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if not df.empty:\n",
    "    # Plot average reward per round\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Average reward per round (all nodes)\n",
    "    ax = axes[0, 0]\n",
    "    if 'my_reward' in df.columns:\n",
    "        round_rewards = df.groupby('round')['my_reward'].agg(['mean', 'std', 'count'])\n",
    "        ax.plot(round_rewards.index, round_rewards['mean'], marker='o', label='Mean Reward')\n",
    "        ax.fill_between(\n",
    "            round_rewards.index, \n",
    "            round_rewards['mean'] - round_rewards['std'],\n",
    "            round_rewards['mean'] + round_rewards['std'],\n",
    "            alpha=0.3\n",
    "        )\n",
    "        ax.set_xlabel('Round')\n",
    "        ax.set_ylabel('Reward')\n",
    "        ax.set_title('Average Reward per Round (All Nodes)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Reward per node\n",
    "    ax = axes[0, 1]\n",
    "    if 'my_reward' in df.columns:\n",
    "        node_rewards = df.groupby('node_id')['my_reward'].mean().sort_values()\n",
    "        node_rewards.plot(kind='barh', ax=ax)\n",
    "        ax.set_xlabel('Average Reward')\n",
    "        ax.set_ylabel('Node ID')\n",
    "        ax.set_title('Average Reward by Node')\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 3. Total agents per round\n",
    "    ax = axes[1, 0]\n",
    "    if 'total_agents' in df.columns:\n",
    "        agents_per_round = df.groupby('round')['total_agents'].mean()\n",
    "        ax.plot(agents_per_round.index, agents_per_round.values, marker='o', color='green')\n",
    "        ax.set_xlabel('Round')\n",
    "        ax.set_ylabel('Number of Agents')\n",
    "        ax.set_title('Active Agents per Round')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Reward distribution\n",
    "    ax = axes[1, 1]\n",
    "    if 'my_reward' in df.columns:\n",
    "        df['my_reward'].hist(bins=30, ax=ax, edgecolor='black')\n",
    "        ax.set_xlabel('Reward')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Reward Distribution')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ No metrics to plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rewards-over-time"
   },
   "outputs": [],
   "source": [
    "# Plot rewards over time for each node\n",
    "if not df.empty and 'my_reward' in df.columns:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    for node_id in df['node_id'].unique():\n",
    "        node_data = df[df['node_id'] == node_id].sort_values('round')\n",
    "        plt.plot(node_data['round'], node_data['my_reward'], \n",
    "                marker='o', label=node_id[:16], alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Round')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.title('Reward Over Time by Node')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ No reward data to plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rollouts-header"
   },
   "source": [
    "## 5. Rollout Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "list-rollouts"
   },
   "outputs": [],
   "source": [
    "def count_rollouts_by_round(exp_path):\n",
    "    \"\"\"Count rollout files by round.\"\"\"\n",
    "    rollouts_dir = f\"{exp_path}/rollouts\"\n",
    "    \n",
    "    if not os.path.exists(rollouts_dir):\n",
    "        return {}\n",
    "    \n",
    "    rollout_counts = {}\n",
    "    \n",
    "    for round_dir in os.listdir(rollouts_dir):\n",
    "        if not round_dir.startswith('round_'):\n",
    "            continue\n",
    "        \n",
    "        round_num = int(round_dir.split('_')[1])\n",
    "        round_path = f\"{rollouts_dir}/{round_dir}\"\n",
    "        \n",
    "        total_files = 0\n",
    "        for stage_dir in os.listdir(round_path):\n",
    "            stage_path = f\"{round_path}/{stage_dir}\"\n",
    "            if os.path.isdir(stage_path):\n",
    "                total_files += len([f for f in os.listdir(stage_path) if f.endswith('.json')])\n",
    "        \n",
    "        rollout_counts[round_num] = total_files\n",
    "    \n",
    "    return rollout_counts\n",
    "\n",
    "# Count and display rollouts\n",
    "rollout_counts = count_rollouts_by_round(EXPERIMENT_PATH)\n",
    "\n",
    "if rollout_counts:\n",
    "    print(\"ðŸ“ Rollout Files by Round:\")\n",
    "    print(\"=\"*40)\n",
    "    for round_num in sorted(rollout_counts.keys()):\n",
    "        count = rollout_counts[round_num]\n",
    "        print(f\"  Round {round_num:3d}: {count:3d} files\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total: {sum(rollout_counts.values())} rollout files\")\n",
    "    \n",
    "    # Plot rollout counts\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    rounds = sorted(rollout_counts.keys())\n",
    "    counts = [rollout_counts[r] for r in rounds]\n",
    "    plt.bar(rounds, counts, color='steelblue', edgecolor='black')\n",
    "    plt.xlabel('Round')\n",
    "    plt.ylabel('Number of Rollout Files')\n",
    "    plt.title('Rollout Files per Round')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âŒ No rollout files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inspect-rollout"
   },
   "outputs": [],
   "source": [
    "# Inspect a specific rollout file\n",
    "def get_latest_rollout(exp_path):\n",
    "    \"\"\"Get the most recent rollout file.\"\"\"\n",
    "    rollouts_dir = f\"{exp_path}/rollouts\"\n",
    "    \n",
    "    if not os.path.exists(rollouts_dir):\n",
    "        return None\n",
    "    \n",
    "    latest_file = None\n",
    "    latest_time = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(rollouts_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                filepath = os.path.join(root, file)\n",
    "                mtime = os.path.getmtime(filepath)\n",
    "                if mtime > latest_time:\n",
    "                    latest_time = mtime\n",
    "                    latest_file = filepath\n",
    "    \n",
    "    return latest_file\n",
    "\n",
    "latest_rollout = get_latest_rollout(EXPERIMENT_PATH)\n",
    "\n",
    "if latest_rollout:\n",
    "    print(f\"ðŸ“„ Latest Rollout File:\")\n",
    "    print(f\"   {latest_rollout}\")\n",
    "    print(\"\\nContent preview:\")\n",
    "    \n",
    "    with open(latest_rollout) as f:\n",
    "        rollout_data = json.load(f)\n",
    "    \n",
    "    print(f\"\\n  Peer ID: {rollout_data.get('peer_id', 'unknown')}\")\n",
    "    print(f\"  Round: {rollout_data.get('round', '?')}\")\n",
    "    print(f\"  Stage: {rollout_data.get('stage', '?')}\")\n",
    "    \n",
    "    if 'rollouts' in rollout_data:\n",
    "        total_rollouts = sum(len(v) for v in rollout_data['rollouts'].values())\n",
    "        print(f\"  Total rollouts: {total_rollouts}\")\n",
    "        print(f\"  Batches: {list(rollout_data['rollouts'].keys())}\")\n",
    "else:\n",
    "    print(\"âŒ No rollout files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "errors-header"
   },
   "source": [
    "## 6. Error Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-errors"
   },
   "outputs": [],
   "source": [
    "def check_for_issues(exp_path):\n",
    "    \"\"\"Check for common issues.\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # Check if state file exists\n",
    "    state_file = f\"{exp_path}/state/current_state.json\"\n",
    "    if not os.path.exists(state_file):\n",
    "        issues.append(\"âš ï¸ State file missing - coordinator may not be running\")\n",
    "    \n",
    "    # Check for peers\n",
    "    peers_dir = f\"{exp_path}/peers\"\n",
    "    if not os.path.exists(peers_dir) or not os.listdir(peers_dir):\n",
    "        issues.append(\"âš ï¸ No peers registered - nodes may not have started\")\n",
    "    \n",
    "    # Check for recent activity\n",
    "    if os.path.exists(state_file):\n",
    "        with open(state_file) as f:\n",
    "            state = json.load(f)\n",
    "            last_update = state.get('timestamp', 0)\n",
    "            if last_update > 0:\n",
    "                time_since_update = datetime.now().timestamp() - last_update\n",
    "                if time_since_update > 600:  # 10 minutes\n",
    "                    issues.append(f\"âš ï¸ No activity for {int(time_since_update/60)} minutes - nodes may be stuck\")\n",
    "    \n",
    "    # Check for logs\n",
    "    logs_dir = f\"{exp_path}/logs\"\n",
    "    if not os.path.exists(logs_dir) or not os.listdir(logs_dir):\n",
    "        issues.append(\"âš ï¸ No log files - training may not have started\")\n",
    "    \n",
    "    # Check for rollouts\n",
    "    rollouts_dir = f\"{exp_path}/rollouts\"\n",
    "    if not os.path.exists(rollouts_dir) or not os.listdir(rollouts_dir):\n",
    "        issues.append(\"âš ï¸ No rollout files - nodes may not be sharing data\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "print(\"ðŸ” Checking for issues...\\n\")\n",
    "issues = check_for_issues(EXPERIMENT_PATH)\n",
    "\n",
    "if issues:\n",
    "    print(\"Issues found:\")\n",
    "    for issue in issues:\n",
    "        print(f\"  {issue}\")\n",
    "else:\n",
    "    print(\"âœ… No issues detected - experiment running normally!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-header"
   },
   "source": [
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary-stats"
   },
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"=\"*60)\n",
    "    print(\"ðŸ“ˆ TRAINING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nExperiment: {EXPERIMENT_NAME}\")\n",
    "    print(f\"Total Rounds: {df['round'].max() + 1}\")\n",
    "    print(f\"Total Nodes: {df['node_id'].nunique()}\")\n",
    "    print(f\"Total Metrics: {len(df)}\")\n",
    "    \n",
    "    if 'my_reward' in df.columns:\n",
    "        print(f\"\\nReward Statistics:\")\n",
    "        print(f\"  Mean:   {df['my_reward'].mean():.4f}\")\n",
    "        print(f\"  Median: {df['my_reward'].median():.4f}\")\n",
    "        print(f\"  Std:    {df['my_reward'].std():.4f}\")\n",
    "        print(f\"  Min:    {df['my_reward'].min():.4f}\")\n",
    "        print(f\"  Max:    {df['my_reward'].max():.4f}\")\n",
    "    \n",
    "    if 'datetime' in df.columns:\n",
    "        duration = df['datetime'].max() - df['datetime'].min()\n",
    "        print(f\"\\nTraining Duration: {duration}\")\n",
    "    \n",
    "    print(\"\\nPer-Node Statistics:\")\n",
    "    if 'my_reward' in df.columns:\n",
    "        node_stats = df.groupby('node_id')['my_reward'].agg(['count', 'mean', 'std'])\n",
    "        node_stats.columns = ['Metrics', 'Avg Reward', 'Std Dev']\n",
    "        print(node_stats.to_string())\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"âš ï¸ No metrics available for summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auto-refresh-header"
   },
   "source": [
    "## 8. Auto-Refresh Status (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auto-refresh"
   },
   "outputs": [],
   "source": [
    "# Auto-refresh status every 30 seconds\n",
    "# WARNING: This will run indefinitely until you stop it manually\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "REFRESH_INTERVAL = 30  # seconds\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        status = get_experiment_status(EXPERIMENT_PATH)\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(f\"ðŸ“Š LIVE STATUS: {EXPERIMENT_NAME}\")\n",
    "        print(f\"ðŸ”„ Auto-refreshing every {REFRESH_INTERVAL}s (Press â–  to stop)\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Current Round:  {status['round']}\")\n",
    "        print(f\"Current Stage:  {status['stage']}\")\n",
    "        print(f\"Active Peers:   {status['num_peers']}\")\n",
    "        \n",
    "        if status['last_updated'] > 0:\n",
    "            last_update = datetime.fromtimestamp(status['last_updated'])\n",
    "            print(f\"Last Updated:   {last_update.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        print(f\"\\nNext refresh:   {datetime.now().strftime('%H:%M:%S')} + {REFRESH_INTERVAL}s\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        time.sleep(REFRESH_INTERVAL)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâœ‹ Auto-refresh stopped\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
